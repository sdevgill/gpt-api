{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the API key and relevant Python libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQH0cFUQMLZ1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv())\n",
        "\n",
        "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Set this to `True` if you need GPT4. If not, the code will use GPT-3.5.\n",
        "GPT4 = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Helper class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GYCp4HzQ9_X"
      },
      "outputs": [],
      "source": [
        "class Conversation:\n",
        "    \"\"\"\n",
        "    This class helps me keep the context of a conversation. It's not\n",
        "    sophisticated at all and it simply regulates the number of messages in the\n",
        "    context window.\n",
        "\n",
        "    You could try something much more involved, like counting the number of\n",
        "    tokens and limiting. Even better: you could use the API to summarize the\n",
        "    context and reduce its length.\n",
        "\n",
        "    But this is simple enough and works well for what I need.\n",
        "    \"\"\"\n",
        "\n",
        "    messages = None\n",
        "\n",
        "    def __init__(self):\n",
        "        # Here is where you can add some personality to your assistant, or\n",
        "        # play with different prompting techniques to improve your results.\n",
        "        Conversation.messages = [\n",
        "            {\n",
        "                \"role\": \"system\",\n",
        "                \"content\": (\n",
        "                    \"You are a helpful, polite, old English assistant. Answer \"\n",
        "                    \"the user prompt with a bit of humor.\"\n",
        "                ),\n",
        "            }\n",
        "        ]\n",
        "\n",
        "\n",
        "    def answer(self, prompt):\n",
        "        \"\"\"\n",
        "        This is the function I use to ask questions.\n",
        "        \"\"\"\n",
        "        self._update(\"user\", prompt)\n",
        "\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4\" if GPT4 else \"gpt-3.5-turbo\",\n",
        "            messages=Conversation.messages,\n",
        "            temperature=0,\n",
        "        )\n",
        "\n",
        "        self._update(\"assistant\", response.choices[0].message.content)\n",
        "\n",
        "        token_dict = self._get_tokens(response)\n",
        "        self._save_to_file(response.choices[0].message[\"content\"], token_dict, 'chats.txt')\n",
        "\n",
        "        return response.choices[0].message[\"content\"], token_dict\n",
        "\n",
        "    def _update(self, role, content):\n",
        "        Conversation.messages.append({\n",
        "            \"role\": role,\n",
        "            \"content\": content,\n",
        "        })\n",
        "\n",
        "        # This is a rough way to keep the context size manageable.\n",
        "        if len(Conversation.messages) > 20:\n",
        "            Conversation.messages.pop(0)\n",
        "\n",
        "    \n",
        "    def _get_tokens(self, response):\n",
        "        return {\n",
        "            \"prompt_tokens\": response[\"usage\"][\"prompt_tokens\"],\n",
        "            \"completion_tokens\": response[\"usage\"][\"completion_tokens\"],\n",
        "            \"total_tokens\": response[\"usage\"][\"total_tokens\"],\n",
        "        }\n",
        "    \n",
        "\n",
        "    def _save_to_file(self, response, token_dict, filename='chats.txt'):\n",
        "        with open(filename, 'a') as f:\n",
        "            for message in Conversation.messages:\n",
        "                if message['role'] == 'user':\n",
        "                    f.write('User: ' + message['content'] + '\\n')\n",
        "                elif message['role'] == 'system':\n",
        "                    f.write('System: ' + message['content'] + '\\n')\n",
        "\n",
        "            f.write('\\n')\n",
        "            f.write('Response: ' '\\n' + str(response) + '\\n')\n",
        "            f.write('\\n')\n",
        "            f.write('Token Dict: ' + str(token_dict) + '\\n')\n",
        "            f.write('\\n' + '--------------------------------------------' + '\\n')\n",
        "            f.write('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkSjhVDvUZHa"
      },
      "source": [
        "Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDXDTbooM8mE"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"\n",
        "What should I wear to a fancy restaurant?\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM1NvWGOUfOa"
      },
      "source": [
        "Create a new instance of `Conversation` whenever you want to clear the context."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "-vgRJ1NDMWFP",
        "outputId": "f5aeb674-a973-40b0-ea93-9c9385ff79ed"
      },
      "outputs": [],
      "source": [
        "conversation = Conversation()\n",
        "\n",
        "response, token_dict = conversation.answer(prompt)\n",
        "print(response)\n",
        "print(token_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9k5x7gvUUn5z"
      },
      "source": [
        "I can now ask a question and the API will know what happened before"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "MY06L5jvNMNQ",
        "outputId": "fe38a61d-7c80-4455-8c32-37a1adaa3fc7"
      },
      "outputs": [],
      "source": [
        "conversation.answer(\"What about an overshirt?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "conversation.answer(\"What is 2 + 2\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
